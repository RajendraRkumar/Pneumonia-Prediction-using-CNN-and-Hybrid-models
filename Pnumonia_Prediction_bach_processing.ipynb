{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e4c22d-a3b4-4845-94dc-7b34b3bf06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fccd3bb-e98d-4d10-82b8-4956da8f0ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 30 01:00:35 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:01:00.0 Off |                    0 |\n",
      "|  0%   37C    P0             75W /  300W |   40839MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A40                     On  |   00000000:23:00.0 Off |                    0 |\n",
      "|  0%   37C    P0             77W /  300W |   43235MiB /  46068MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A40                     On  |   00000000:41:00.0 Off |                    0 |\n",
      "|  0%   28C    P8             23W /  300W |       4MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A40                     On  |   00000000:61:00.0 Off |                    0 |\n",
      "|  0%   28C    P8             23W /  300W |       4MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA A40                     On  |   00000000:81:00.0 Off |                    0 |\n",
      "|  0%   70C    P0            283W /  300W |   41347MiB /  46068MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA A40                     On  |   00000000:A1:00.0 Off |                    0 |\n",
      "|  0%   71C    P0            276W /  300W |   41379MiB /  46068MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA A40                     On  |   00000000:C1:00.0 Off |                    0 |\n",
      "|  0%   69C    P0            278W /  300W |   41091MiB /  46068MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA A40                     On  |   00000000:E1:00.0 Off |                    0 |\n",
      "|  0%   68C    P0            281W /  300W |   41379MiB /  46068MiB |    100%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1078005      C   python                                      40830MiB |\n",
      "|    1   N/A  N/A   1078005      C   python                                      41376MiB |\n",
      "|    1   N/A  N/A   1088965      C   /l/anaconda3-2024.02/bin/python              1844MiB |\n",
      "|    4   N/A  N/A   1079588      C   ...cratch/youwyu/conda/edm2/bin/python      41338MiB |\n",
      "|    5   N/A  N/A   1079589      C   ...cratch/youwyu/conda/edm2/bin/python      41370MiB |\n",
      "|    6   N/A  N/A   1079590      C   ...cratch/youwyu/conda/edm2/bin/python      41082MiB |\n",
      "|    7   N/A  N/A   1079591      C   ...cratch/youwyu/conda/edm2/bin/python      41370MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi # Checking nvidia cores and useage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2cac7c-710d-45f6-b896-1ab6806debad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 1) DATA PREPARATION (Both 1-channel and 3-channel)\n",
    "############################################################\n",
    "\n",
    "# dataset directory structure\n",
    "data_dir = \"/nobackup/kumar13/data/ChestXRay2017/chest_xray\"\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Transform for 1-channel (used by CNN and CNN-LSTM )\n",
    "transform_1ch = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Transform for 3-channel (used by AlexNet, ResNet, and Transformer models)\n",
    "transform_3ch = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a102ec02-9e9d-40fe-8a48-3cddd3d9710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-channel datasets/loaders\n",
    "train_data_1ch = datasets.ImageFolder(train_dir, transform=transform_1ch)\n",
    "test_data_1ch = datasets.ImageFolder(test_dir, transform=transform_1ch)\n",
    "train_loader_1ch = DataLoader(train_data_1ch, batch_size=32, shuffle=True)\n",
    "test_loader_1ch = DataLoader(test_data_1ch, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3-channel datasets/loaders\n",
    "train_data_3ch = datasets.ImageFolder(train_dir, transform=transform_3ch)\n",
    "test_data_3ch = datasets.ImageFolder(test_dir, transform=transform_3ch)\n",
    "train_loader_3ch = DataLoader(train_data_3ch, batch_size=32, shuffle=True)\n",
    "test_loader_3ch = DataLoader(test_data_3ch, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc8c770-2fbe-4b9d-abd4-f5a71aca6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-GPU configuration\n",
    "# \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf7df77-8251-4e11-b8c0-897c68f2891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 2) SIMPLE CNN \n",
    "############################################################\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 56 * 56, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = SimpleCNN()\n",
    "cnn_model = nn.DataParallel(cnn_model, device_ids=[0,1,2,3]).to(device)\n",
    "\n",
    "criterion_cnn = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a664bbf-611e-448a-a37b-ff766c6e7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260933bc-ac57-4627-913a-b8b5f86395f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4898a0-14e5-4381-a735-ecf43ebb14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 3) CNN-LSTM HYBRID MODEL\n",
    "############################################################\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(128, 128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, timesteps, C, H, W = x.size()\n",
    "        x = x.view(batch_size * timesteps, C, H, W)\n",
    "        cnn_out = self.cnn(x)\n",
    "        cnn_out = self.global_pool(cnn_out)\n",
    "        cnn_out = cnn_out.view(batch_size, timesteps, -1)\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        return self.fc(lstm_out[:, -1, :])\n",
    "\n",
    "cnn_lstm_model = CNN_LSTM()\n",
    "cnn_lstm_model = nn.DataParallel(cnn_lstm_model, device_ids=[0,1,2,3]).to(device)\n",
    "\n",
    "criterion_cnn_lstm = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_lstm = optim.Adam(cnn_lstm_model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492981d4-14c3-44f1-8a68-9383222a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cnn_lstm(model, loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            # The usr code adds an extra time dimension\n",
    "            images = images.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9cca468-c4fd-40ea-9385-401e8e88ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_cnn_lstm(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.unsqueeze(1).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45881ed4-65f5-45c2-93f1-2916d994474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 4) ALEXNET\n",
    "############################################################\n",
    "\n",
    "from torchvision.models import alexnet\n",
    "\n",
    "alexnet_model = alexnet(weights=None)\n",
    "alexnet_model.classifier[6] = nn.Linear(4096, 2)\n",
    "alexnet_model = nn.DataParallel(alexnet_model, device_ids=[0,1,2,3]).to(device)\n",
    "\n",
    "criterion_alex = nn.CrossEntropyLoss()\n",
    "optimizer_alex = optim.Adam(alexnet_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e4d525-3de4-41e8-8b4a-4bc1a3fad6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 5) RESNET (for example ResNet18)\n",
    "############################################################\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "resnet_model = resnet18(weights=None)\n",
    "num_ftrs = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 2)\n",
    "resnet_model = nn.DataParallel(resnet_model, device_ids=[0,1,2,3]).to(device)\n",
    "\n",
    "criterion_resnet = nn.CrossEntropyLoss()\n",
    "optimizer_resnet = optim.Adam(resnet_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe56e86-7c4f-4317-96a3-d85c69f4baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 6) VISION TRANSFORMER (Using timm)\n",
    "############################################################\n",
    "\n",
    "# \n",
    "try:\n",
    "    import timm\n",
    "    vit_model = timm.create_model(\"vit_base_patch16_224\", pretrained=False, num_classes=2)\n",
    "    vit_model = nn.DataParallel(vit_model, device_ids=[0,1,2,3]).to(device)\n",
    "    criterion_vit = nn.CrossEntropyLoss()\n",
    "    optimizer_vit = optim.Adam(vit_model.parameters(), lr=0.001)\n",
    "    has_timm = True\n",
    "except ImportError:\n",
    "    print(\"Warning: timm is not installed. Vision Transformer code will be skipped.\")\n",
    "    vit_model = None\n",
    "    has_timm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bce38ba-37a2-49de-a72a-6ebd766c82e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAINING CNN ====================\n",
      "Epoch [1/5] - Loss: 0.2524\n",
      "Epoch [2/5] - Loss: 0.0718\n",
      "Epoch [3/5] - Loss: 0.0548\n",
      "Epoch [4/5] - Loss: 0.0401\n",
      "Epoch [5/5] - Loss: 0.0264\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 7) TRAIN AND TEST ALL MODELS\n",
    "############################################################\n",
    "\n",
    "print(\"\\n==================== TRAINING CNN ====================\")\n",
    "train_model(cnn_model, train_loader_1ch, criterion_cnn, optimizer_cnn, num_epochs=5)\n",
    "cnn_train_acc = test_accuracy(cnn_model, train_loader_1ch)\n",
    "cnn_test_acc = test_accuracy(cnn_model, test_loader_1ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c84e52c-ae6a-4985-85c9-1e47e3df045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAINING CNN-LSTM ====================\n",
      "Epoch [1/5] - Loss: 0.5781\n",
      "Epoch [2/5] - Loss: 0.5325\n",
      "Epoch [3/5] - Loss: 0.4362\n",
      "Epoch [4/5] - Loss: 0.3445\n",
      "Epoch [5/5] - Loss: 0.3035\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==================== TRAINING CNN-LSTM ====================\")\n",
    "train_model_cnn_lstm(cnn_lstm_model, train_loader_1ch, criterion_cnn_lstm, optimizer_cnn_lstm, num_epochs=5)\n",
    "cnn_lstm_train_acc = test_accuracy_cnn_lstm(cnn_lstm_model, train_loader_1ch)\n",
    "cnn_lstm_test_acc = test_accuracy_cnn_lstm(cnn_lstm_model, test_loader_1ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65598245-35e9-45ac-bab9-5ef4dd66b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAINING ALEXNET ====================\n",
      "Epoch [1/5] - Loss: 0.4448\n",
      "Epoch [2/5] - Loss: 0.2106\n",
      "Epoch [3/5] - Loss: 0.1346\n",
      "Epoch [4/5] - Loss: 0.1242\n",
      "Epoch [5/5] - Loss: 0.1191\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==================== TRAINING ALEXNET ====================\")\n",
    "train_model(alexnet_model, train_loader_3ch, criterion_alex, optimizer_alex, num_epochs=5)\n",
    "alexnet_train_acc = test_accuracy(alexnet_model, train_loader_3ch)\n",
    "alexnet_test_acc = test_accuracy(alexnet_model, test_loader_3ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a220d41-4bfa-46e5-b14a-c8bde26ff861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAINING RESNET ====================\n",
      "Epoch [1/5] - Loss: 0.2595\n",
      "Epoch [2/5] - Loss: 0.1435\n",
      "Epoch [3/5] - Loss: 0.1169\n",
      "Epoch [4/5] - Loss: 0.0756\n",
      "Epoch [5/5] - Loss: 0.0821\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==================== TRAINING RESNET ====================\")\n",
    "train_model(resnet_model, train_loader_3ch, criterion_resnet, optimizer_resnet, num_epochs=5)\n",
    "resnet_train_acc = test_accuracy(resnet_model, train_loader_3ch)\n",
    "resnet_test_acc = test_accuracy(resnet_model, test_loader_3ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7586c9-1d21-48a6-ba4a-b5ba566a723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== TRAINING VISION TRANSFORMER ====================\n",
      "Epoch [1/5] - Loss: 0.6956\n",
      "Epoch [2/5] - Loss: 0.5887\n",
      "Epoch [3/5] - Loss: 0.5815\n",
      "Epoch [4/5] - Loss: 0.6010\n",
      "Epoch [5/5] - Loss: 0.5717\n"
     ]
    }
   ],
   "source": [
    "if has_timm:\n",
    "    print(\"\\n==================== TRAINING VISION TRANSFORMER ====================\")\n",
    "    train_model(vit_model, train_loader_3ch, criterion_vit, optimizer_vit, num_epochs=5)\n",
    "    vit_train_acc = test_accuracy(vit_model, train_loader_3ch)\n",
    "    vit_test_acc = test_accuracy(vit_model, test_loader_3ch)\n",
    "else:\n",
    "    vit_train_acc = None\n",
    "    vit_test_acc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e0b297f-582f-4f32-8b83-c91c82631987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== ACCURACIES ====================\n",
      "| Model               | Train Acc  | Test Acc   |\n",
      "|:--------------------|-----------:|-----------:|\n",
      "| CNN                 | 0.9954     | 0.7756     |\n",
      "| CNN-LSTM            | 0.8362 | 0.6859 |\n",
      "| AlexNet             | 0.9736  | 0.7885  |\n",
      "| ResNet18            | 0.9841   | 0.7997   |\n",
      "| ViT (Base/16)       | 0.7410      | 0.6346      |\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 8) SHOW ACCURACIES\n",
    "############################################################\n",
    "\n",
    "print(\"\\n==================== ACCURACIES ====================\")\n",
    "header = \"| Model               | Train Acc  | Test Acc   |\"\n",
    "line   = \"|:--------------------|-----------:|-----------:|\"\n",
    "print(header)\n",
    "print(line)\n",
    "\n",
    "print(f\"| CNN                 | {cnn_train_acc:.4f}     | {cnn_test_acc:.4f}     |\")\n",
    "print(f\"| CNN-LSTM            | {cnn_lstm_train_acc:.4f} | {cnn_lstm_test_acc:.4f} |\")\n",
    "print(f\"| AlexNet             | {alexnet_train_acc:.4f}  | {alexnet_test_acc:.4f}  |\")\n",
    "print(f\"| ResNet18            | {resnet_train_acc:.4f}   | {resnet_test_acc:.4f}   |\")\n",
    "if has_timm:\n",
    "    print(f\"| ViT (Base/16)       | {vit_train_acc:.4f}      | {vit_test_acc:.4f}      |\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd6d0e-0e9b-4bfd-9dfa-64f2716e79cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
